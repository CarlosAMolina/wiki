# S3

## Introducción

S3 = Simple Storage Service

Es un servicio que funciona en la zona pública de AWS.

Los datos se guardan en una región de AWS, aunque puede configurarse que se repliquen en otras regiones.

Tiene resilencia regional.

Por defecto es un servicio privado.

## Composición

### Objects

Son los datos almacenados. Puede pensarse en ellos como en archivos.

Formado por varios componentes (2 son los componentes principales):

- Key, identifica de manera única al objeto en un bucket. Puede pensarse como el nombre del archivo.
- Value: es el contenido que se está almacenando. Puede tener de 0 bytes a 5 TB.
- Otros componentes:
  - Version ID.
  - Metadata.
  - Access Control.
  - Subresources.

### Buckets

Es un objeto contenedor de otros objetos.

Se crea en una región. Cuando accedes al servicio S3 en la consola de AWS, se muestran todos los buckets de la cuenta en todas las regiones y en la parte de arriba a la derecha no puedes seleccionar una región, la región se selecciona al crear un bucket.

No existe el concepto de tipo de archivo (.jpg, .csv, etc), los objetos se identifican por su key.

Restricciones:

- Su nombre debe ser único globalmente (no puede existir en ninguna cuenta de AWS, ni en cuentas que no sean nuestras, tampoco puede existir en ninguna región).
- Su nombre debe tener entre 3 y 63 caracteres, todo minúsculas, sin `_`.
- Su nombre debe comenzar por una letra minúscula o un número.
- No pueden formatearse como una IP, ejemplo `1.1.1.1`.
- Por defecto, hay máximo 100 buckets por cuenta root de AWS; puede ampliarse a 1.000. Si una cuenta tiene X usuarios donde X > máximo número de buckets, cada usuario no podrá tener un bucket, una solución es que múltiples usuarios usen el mismo bucket e ir configurando prefijos para cada usuario.
- No hay límite de número de objetos en un bucket.

### Carpetas en un bucket

No es como un file system porque los objetos se almacenan todos al mismo nivel. A pesar de que en la consola de AWS se muestre que podemos crear carpetas en un bucket, en realidad no hay estructura de carpetas dentro de carpetas. Por ejemplo, si en el bucket `foo` tenemos el objeto `bar/file.txt`, el key del objeto es `bar/file.txt`, aunque la consola presente `bar` como una carpeta, en realidad es parte del key, `bar` es un prefijo.

Si en la consola utilizas la opción de crear una carpeta, en realidad creas un objeto con el nombre indicado. Al subir objetos en esa carpeta, lo que hace es añadir el prefijo del nombre de esa carpeta.

## Qué no es S3

S3 no se puede montar como si fuera un mount point o un volumen; en ese caso hay que usar un block storage (son discos duros virtuales), por ejemplo EBS.

## Consola AWS

Cuando accedes a S3 no te deja seleccionar una región, se selecciona al crear objetos.

## Permisos

Como se dijo, por defecto S3 es un servicio privado.

### Bucket Policies

Es un tipo de Resource Policy.

Pueden configurarse para indicar a quién afecta utilizando direcciones IP, si ha utilizado MFA, etc.

Un bucket solo puede tener un Bucket Policy asociado, pero en el policy pueden definirse múltiples reglas.

### Block public access

Debido a problemas de leaks que hubo en S3, se implementó esta opción que consiste en que independiente de las políticas configuradas puede bloquearse el acceso público activando esta opción.

Permite distintas configuraciones donde se puede elegir si aplica a ACLs o policies, solo para lo nuevo o también para lo ya existente, etc.

Desactivar esta opción no significa que se otorgue al bucket acceso público, esto debe hacerse aparte.

### ACL

ACL = Access Control Lists.

Es un servicio legacy, AWS recomienda utilizar policies.

Sirven para aplicar seguridad (permisos) a un objeto o a un bucket de S3, no puede asociarse a varias cosas por lo que es mejor utilizar policies.

## Coste

El cobro depende de distintos aspectos, descritos [en este link](https://aws.amazon.com/es/s3/pricing/):

Por ejemplo, algunos de los puntos son los siguientes:

- Información almacenada: según la cantidad de GB y el tiempo de almacenamiento.
- Transferencia de datos: tráfico entrante en S3 es gratis pero el saliente depende del número de GB.
- Solicitudes HTTP: según el número y tipo de peticiones (GET, POST, etc.).

## Versionado

Se configura a nivel de bucket.

Una vez activado el versionado en un bucket, no puede desactivarse. Sí podemos suspender el versionado, en este caso los nuevos objetos que se suban no tendrán versión pero las anteriores se mantendrán (y ocuparán espacio); más tarde puede volverse a activar.

Los objetos en un bucket tienen un atributo ID para la versión; con valor nulo de estar el versionado deshabilitado y de estar activado es un valor (no numérico) que cambia en cada versión.

Con el versionado activado, un objeto no se elimina, sino que se añade un marcador de borrado (este marcador es una nueva versión del objeto); en este momento no se mostrará el objeto en la consola de AWS. De eliminar esta marca vuelve a estar disponible la última versión. Para eliminar un objeto con versionado, especificamos el ID de la versión a eliminar.

La versión actual de un objeto es la máxima disponible.

AWS ofrece el MFA delete, que significa que utiliza MFA para cambiar el estado de la versión y borrar versiones.

## Performance

Hay que tener en cuenta que, cuando subimos un archivo de S3, este se transfiere como un único data stream a través de internet; en caso de error hay que volver a transmitir el data stream completo.

Para evitar problemas o mejorar la velocidad de transmisión, hay opciones como:

- Subirlo en partes: tiene la ventaja de retransmitir los errores que ocurran.
- Utilizar S3 Accelerated Transfer: en lugar de viajar la información por el internet público, se utilizan los Edge Locations y el archivo viaja a S3 a través de la red de AWS; lo que es más rápido.

### Limitaciones

Si se sube un objeto, el data stream puede tener como máximo 5 GB.

Para poder subir el objeto en partes, el tamaño debe ser mayor a 100 MB. Como máximo el archivo se puede dividir en 10.000 partes, siendo cada una entre 5 MB y 5 GB, a excepción de la última parte que puede ser menor a 5 MB.

## Cifrado

En S3 lo que se cifra no es el bucket, se cifran los objetos que contiene; cada objeto puede tener distinta configuración de cifrado.

Hay dos tipos de cifrado (está permitido emplear ambos métodos a la vez):

- Client side encryption: cliente cifra los datos antes de enviarlos a S3.
- Server side encryption (SSE): S3 es el encargado de proceso de cifrado.

En ambos casos, entre el cliente y S3 los objetos se transmiten mediante una transmisión cifrada (HTTPs), aunque en el caso del SSE, los objetos no están cifrados dentro de la transmisión y se cifran en S3.

Elegir el método dependen de la regulación ya que, hay que tener en cuenta algunos aspectos como que hay que confiar en S3 durante el proceso de cifrado y que hay momentos en que los objetos están en texto plano; así como quién puede descifrarlos como veremos a continuación.

Resumen de las diferencias sobre el responsable de cada acción:

Método                 | Gestión claves cifrado | Proceso cifrado | Extra
-----------------------|------------------------|-----------------|-----------------------------------------------------
Client-Side Encryption | Usuario                | Usuario         | S3 no ve objetos en texto plano.
SSE-C                  | Usuario                | S3              |
SSE-S3                 | S3                     | S3              | Usuario no controla las claves. No hay role separation.
SSE-KMS                | S3 + KMS               | S3              | Usuario controla las claves (ejm, rotación). Hay role separation.

Por ejemplo sobre role separation es que el administrador del bucket que los gestiona se le pueda negar el poder descifrarlos.

### SSE

Los recursos de CPU necesarios para cifrar se consumen en S3.

Actualmente, es obligatorio en los buckets.

Podemos elegir entre los siguientes tipos de cifrado:

- SSE-C (SSE with Customer-Provided keys): S3 cifra y descifra utilizando las Keys o Key que aporta el usuario. Confías en que S3 no almacenará las claves del cliente.
- SSE-S3 (SEE with Amazon-S3 Managed Keys): por defecto S3 usa este. S3 cifra el objeto con una clave única para cada objeto. El usuario no controla las claves (creación, rotación etc...) y no hay role separation.
- SSE-KMS (SEE with KMS Keys Stored in AWS KMS): a diferencia que en SSE-S3, el servicio que gestiona las claves es KMS; el cifrado lo sigue haciendo S3. Permite control de las claves (rotación, auditoría de quién las utiliza, role separation, etc). Creo que también utiliza una clave única por objeto.

En SSE-KMS se utiliza DEK (ver sección de KMS), creo que en SSE-S3 también.

Para evitar las limitaciones en el número de llamadas a KMS, costes, etc; puede utilizarse un Bucket Key, para que, en lugar de utilizar una clave KMS única por cada objeto; se genera una temporal a utilizar para todos.

## Tipos de almacenamiento

[Enlace](https://aws.amazon.com/es/s3/storage-classes/).

### S3 Standard

Utilizado por defecto.

Los objetos se replican por lo menos en 3 AZ, por lo que no le afectan fallos en una AZ.

Cobro:

- GB almacenados al mes.
- GB transferido como output (input no cobran).
- Por cada 1.000 peticiones.

Utilizarlo para datos accedidos frecuentemente.

## S3 Standard-IA

IA = Acceso Infrecuente.

Los objetos se replican de igual manera que en S3 Standard.

Almacenarlos cuesta menos dinero.

Tiene un coste adicional a S3 Standard al obtener objetos.

Se cobra un tiempo de almacenaje mínimo de 30 días, aunque los objetos estén menos tiempo.

S3 cobra un almacenamiento mínimo de 128 KB por objeto aunque ocupe menos.

## S3 One Zone-IA

Más barato que S3 Standard y S3 Standard IA.

Como en S3 Standard IA, tiene cobro por obtener objetos, cobran mínimo 30 días y 128 KB.

Los datos no se replican en otras AZ; solo está en una (los datos sí se replican dentro de la AZ). Por lo que hay más riesgo de pérdida en caso de error en la AZ.

Para evitar pérdida de datos, no utilizar esta opción si no hay replicación en otras regiones.

## S3 Glacier-Instant

Es como S3 Standard-IA pero:

- Almacenamiento de menor coste.
- Obtención de objetos más cara.
- Cobro de tiempo almacenamiento mínimo de 90 días y 180 KB/objeto.

La obtención del objeto es inmediata.

Ejemplo de uso para archivos que se acceden una vez al mes.

## S3 Glacier-Flexible

Es como S3 Standard-IA pero:

- Almacenamiento de menor coste.
- Los objetos no pueden ser públicos porque no se obtienen inmediatamente. Pueden verse los metadatos del objeto pero se requiere un proceso que cuesta dinero; hay varias opciones (de mayor coste cuanto más rápidas sean):
  - Expedited: tarda de 1 a 5 minutos.
  - Standard: de 3 a 5 horas.
  - Bulk: de 5 a 12 horas.
- Cobro de tiempo almacenamiento mínimo de 90 días y 40 KB/objeto.

Ejemplo de uso para archivos que se acceden una vez al año.

## S3 Glacier Deep Archive

- Cobro de tiempo almacenamiento mínimo de 180 días y 40 KB/objeto.
- El proceso para obtener los objetos puede ser:
  - Standard: tarda 12 horas.
  - Bulk: hasta 48 horas.

Ejemplo uso: datos que no se acceden casi nunca como información legal o regulatoria; tampoco es aconsejable usarlo como un primer backup, en todo caso como uno secundario.

## S3 Intelligent-Tiering

Tiene 5 tipos:

- Frequent Access. Similar a S3 Standard.
- Infrequent Access. Similar a S3 Standard-IA.
- Archive Instant Access. Similar a S3 Glacier Instant.
- Archive Access. Similar a S3 Glacier Flexible.
- Deep Archive. Similar a S3 Glacier Deep Archive.

Es inteligente, monitoriza el acceso a los objetos y los mueve automáticamente entre cada tipo  de almacenameinto.

Tiene coste por cada 1.000 objetos monitorizados.

Aconsejable usarlo cuando el acceso a los objetos es variable o desconocido.

## S3 Lifecycle configuration

Son reglas que permiten cambiar el modo de almacenamiento (transition actions) o expirar objetos (expiration actions) o sus versiones.

Pueden configurarse sobre buckets o sobre grupos de objetos (se toman por prefijo o tags).

Excepciones y limitaciones:

- Hay algunos modos de almacenamiento desde los que no se puede pasar a otros. Por ejemplo, de S3 One Zone-IA no puede cambiarse a S3 Glacier-Instant Retrieval.
- La dirección del cambio es descendente (ejemplo de S3 Standard a S3 Standard IA), no ascendente (ejm. de S3 Standard IA a S3 Standard).
- Hay algunos estados en el que hay que estar un tiempo mínimo antes de cambiar, ejm. para ir de S3 Standard a S3 Standard-IA o S3 One Zone IA, los objetos deben estar mínimo 30 días en S3 Standard.
- Si tienes una sola regla configurada, no se puede cambiar un estado de S3 Standard a S3 Standrad IA y de ahí a otros en menos de 30 días. De haber 2 o más reglas, esta limitación no aplica.

## S3 Replication

Sirve para que los objetos se repliquen entre un bucket origen y un destino.

## Tipos

Hay dos tipos:

  - Cross-Region Replication (CRR): de un bucket a otro u otros buckets destino en diferentes regiones.
  - Same-Region Replication (SRR): buckets están en la misma región.

En ambos tipos, los buckets pueden estar en la misma o en distintas cuentas de AWS.

## Configuración

Debe especificarse:

- El bucket destino.
- Rol que utilizar.
- En SSR, en la cuenta destino es necesario aplicar un bucket policy porque por defecto no se confía en el rol utilizado para la réplica al pertenecer a otra cuenta.
- Los objetos a replicar. Puede ser:
    - Todos los objetos.
    - Algunos objetos: se filtra por prefijo, tags, o combinación de ellos.
- La clase de almacenamiento en el destino, puede ser distinta a la de origen; por defecto se utiliza la misma.
- El owner de los objetos en la cuenta destino; por defecto es la cuenta origen, pero esto en SRR implica que la cuenta destino no pueda leer los objetos por lo que puede configurarse el owner.
- Replication Time Control (RTC): activando esta opción se garantizar que la réplica ocurre en dentro de los primeros 15 minutos; de no utilizarla, AWS realiza un best effort. Tiene coste adicional.

## Consideraciones

- Por defecto, se replican objetos nuevos a partir de cuándo se activa la réplica. Para replicar objetos existentes, hay que activar esta opción.
- El bucket origen y destino deben tener el versionado activado.
- Por defecto, añadir objetos en el destino no se replican en origen. Pero puede activarse una réplica bidireccional.
- Replicar objetos cifrados con KMS necesita configuración adicional.
- El source bucket necesita tener permisos sobre los objetos a replicar. Puede que esto no ocurra en situaciones como por ejemplo, que otras cuentas puedan escribir en ese bucket.
- No se replican system events (ejemplo cambios hechos en un bucket por una regla lifecycle), solo user events.
- No pueden replicarse objetos que utilicen Glacier o Glaceir Deep Archive.
- Por defecto, no se replica el borrado de objetos, pero puede activarse. Como el versionado está activado, significa que por defecto no se replica el delete mark.

## Presigned URLs

Dan acceso a una persona o aplicación a un objeto de S3. Permiten cargar o descargar objetos.

Si un bucket es privado, es la mejor opción para que alguien sin autorización pueda accede a los objetos porque las otras alternativas tienen puntos en contra:

- Darle una Identidad AWS. Esto para un acceso temporal no es eficiente.
- Darle credenciales AWS. Es un riesgo de seguridad por si otra persona las consigue.
- Hacer el bucket público. Implicaría modificar todos los objetos y puede que algunos deban ser privados.

Al generar estas URLs, se les configura el bucket, objeto, tiempo de expiración y cómo se accede al objeto.

Aspectos a tener en cuenta:

- La identidad que lo genere puede hacerlo sobre objetos a los que no tenga acceso, pero la URL tampoco tendrá acceso.
- Al utilizar la URL, se utilizan los permisos que en ese momento tenga la identidad que lo generó.
- No crear presigned URLs con un rol porque cuando este expire, la URL pierde acceso.

Ejemplo de uso, tenemos en un servidor una aplicación que permite descargar un vídeo de S3, a esa aplicación se le da un IAM user con permisos fijos sobre el objeto, y este IAM creará las presigned URLs cuando se soliciten.
